{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy Induction (attn-only-2l): Drift via Circuit Competition\n",
    "\n",
    "Reproduce martingale drift (order sensitivity) in a minimal circuit where induction heads can exist, and show that ablating those heads collapses the drift toward an order-invariant counting baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook path setup: make repo imports work regardless of where you run this from\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "cwd = Path.cwd().resolve()\n",
    "repo_candidates = [cwd, cwd.parent]\n",
    "repo_root = next((p for p in repo_candidates if (p / 'bayesian_llm').exists()), None)\n",
    "if repo_root is None:\n",
    "    raise RuntimeError(f'Could not find repo root from cwd={cwd}.')\n",
    "\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "\n",
    "print('Repo root:', repo_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies (this notebook assumes you already installed requirements)\n",
    "import pkgutil\n",
    "\n",
    "REQUIRED = ['torch', 'numpy', 'pandas', 'transformer_lens']\n",
    "missing = [p for p in REQUIRED if pkgutil.find_loader(p) is None]\n",
    "print('Missing:', missing if missing else 'None')\n",
    "\n",
    "HAS_CIRCUITSVIS = pkgutil.find_loader('circuitsvis') is not None\n",
    "print('circuitsvis installed:', HAS_CIRCUITSVIS)\n",
    "\n",
    "if missing:\n",
    "    print('Install with: pip install -r ../requirements.txt')\n",
    "if not HAS_CIRCUITSVIS:\n",
    "    print('Install circuitsvis with: pip install circuitsvis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load attn-only-2l (TransformerLens)\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DTYPE = torch.float32 if DEVICE == 'cpu' else torch.float16\n",
    "\n",
    "model = HookedTransformer.from_pretrained('attn-only-2l', device=DEVICE, dtype=DTYPE)\n",
    "print('Loaded attn-only-2l')\n",
    "print('device:', DEVICE, 'dtype:', DTYPE)\n",
    "print('n_layers:', model.cfg.n_layers, 'n_heads:', model.cfg.n_heads, 'd_model:', model.cfg.d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stimuli and verify tokenization (important!)\n",
    "\n",
    "# We predict between exactly two single-token candidates: \" X\" and \" Y\"\n",
    "X_STR = ' X'\n",
    "Y_STR = ' Y'\n",
    "\n",
    "X_ID = model.to_single_token(X_STR)\n",
    "Y_ID = model.to_single_token(Y_STR)\n",
    "\n",
    "print('X_STR token id:', X_ID)\n",
    "print('Y_STR token id:', Y_ID)\n",
    "\n",
    "# Sanity: decode\n",
    "print('decode X:', repr(model.tokenizer.decode([X_ID])))\n",
    "print('decode Y:', repr(model.tokenizer.decode([Y_ID])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct sequences with identical counts but different order\n",
    "\n",
    "# All have 3 X and 3 Y. If the model were a perfect count-based Bayesian updater, predictions should match.\n",
    "SEQUENCES = {\n",
    "    'patterned': ['X','Y','X','Y','X','Y'],\n",
    "    'clumped':   ['X','X','X','Y','Y','Y'],\n",
    "    'mixed':     ['X','Y','Y','X','X','Y'],\n",
    "}\n",
    "\n",
    "def counts(seq):\n",
    "    n_x = sum(t == 'X' for t in seq)\n",
    "    n_y = sum(t == 'Y' for t in seq)\n",
    "    return n_x, n_y\n",
    "\n",
    "for name, seq in SEQUENCES.items():\n",
    "    print(name, seq, 'counts=', counts(seq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order-invariant baselines: Frequentist and Bayesian (Beta-Bernoulli)\n",
    "\n",
    "# Frequentist: p_hat = n_X / (n_X + n_Y)\n",
    "# Bayesian posterior predictive: Beta(alpha,beta) prior -> (alpha+n_X)/(alpha+beta+n)\n",
    "\n",
    "ALPHA = 1.0\n",
    "BETA = 1.0\n",
    "\n",
    "def frequentist_p_x(n_x, n_y):\n",
    "    n = n_x + n_y\n",
    "    return n_x / n if n > 0 else 0.5\n",
    "\n",
    "def bayes_p_x(n_x, n_y, *, alpha=ALPHA, beta=BETA):\n",
    "    n = n_x + n_y\n",
    "    return (alpha + n_x) / (alpha + beta + n)\n",
    "\n",
    "# These should be identical across sequences (same counts).\n",
    "for name, seq in SEQUENCES.items():\n",
    "    n_x, n_y = counts(seq)\n",
    "    print(name, 'freq=', round(frequentist_p_x(n_x,n_y),4), 'bayes=', round(bayes_p_x(n_x,n_y),4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model prediction utilities: logits/probs for next token\n",
    "\n",
    "import torch\n",
    "\n",
    "def make_prompt(seq_tokens):\n",
    "    # Force each token to be preceded by a space by using \"Sequence: \" prefix.\n",
    "    return 'Sequence: ' + ' '.join(seq_tokens)\n",
    "\n",
    "@torch.no_grad()\n",
    "def model_p_x(prompt: str):\n",
    "    # Returns normalized P(X | {X,Y}), plus raw logits and softmax probs for the two tokens.\n",
    "    logits = model(prompt)  # [batch=1, pos, vocab]\n",
    "    last = logits[0, -1, :]\n",
    "\n",
    "    logit_x = float(last[X_ID].item())\n",
    "    logit_y = float(last[Y_ID].item())\n",
    "\n",
    "    probs = torch.softmax(last.float(), dim=-1)\n",
    "    p_x = float(probs[X_ID].item())\n",
    "    p_y = float(probs[Y_ID].item())\n",
    "\n",
    "    norm = p_x + p_y\n",
    "    p_x_norm = p_x / norm if norm > 0 else 0.5\n",
    "    p_y_norm = p_y / norm if norm > 0 else 0.5\n",
    "\n",
    "    return {\n",
    "        'logit_X': logit_x,\n",
    "        'logit_Y': logit_y,\n",
    "        'logit_diff_XminusY': logit_x - logit_y,\n",
    "        'p_X_raw': p_x,\n",
    "        'p_Y_raw': p_y,\n",
    "        'p_X_norm': p_x_norm,\n",
    "        'p_Y_norm': p_y_norm,\n",
    "    }\n",
    "\n",
    "# Quick smoke test\n",
    "print(model_p_x(make_prompt(SEQUENCES['patterned'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline: evaluate patterned/clumped/mixed and compute drift\n",
    "\n",
    "rows = []\n",
    "for name, seq in SEQUENCES.items():\n",
    "    n_x, n_y = counts(seq)\n",
    "    prompt = make_prompt(seq)\n",
    "    out = model_p_x(prompt)\n",
    "\n",
    "    rows.append({\n",
    "        'name': name,\n",
    "        'seq': ' '.join(seq),\n",
    "        'n_X': n_x,\n",
    "        'n_Y': n_y,\n",
    "        'freq_p_X': frequentist_p_x(n_x,n_y),\n",
    "        'bayes_p_X': bayes_p_x(n_x,n_y),\n",
    "        **out,\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values('name')\n",
    "display(df)\n",
    "\n",
    "drift = float(df.p_X_norm.max() - df.p_X_norm.min())\n",
    "print('Drift (max-min) over permutations with same counts:', drift)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Attention with CircuitVis\n",
    "\n",
    "We visualize attention patterns for both layers. Induction heads typically show a distinctive pattern where they attend to positions that enable copying of the next token after a previous occurrence of the same context token.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with cache and visualize attention patterns for each sequence\n",
    "\n",
    "import pkgutil\n",
    "from IPython.display import display\n",
    "\n",
    "if pkgutil.find_loader('circuitsvis') is None:\n",
    "    raise RuntimeError('circuitsvis not installed. Run: pip install circuitsvis')\n",
    "\n",
    "import circuitsvis as cv\n",
    "\n",
    "for name, seq in SEQUENCES.items():\n",
    "    prompt = make_prompt(seq)\n",
    "    logits, cache = model.run_with_cache(prompt)\n",
    "    tokens = model.to_str_tokens(prompt)\n",
    "\n",
    "    print('===', name, '===')\n",
    "    print('Tokens:', tokens)\n",
    "\n",
    "    for layer in range(model.cfg.n_layers):\n",
    "        # cache['pattern', layer] has shape [batch, head, query, key]\n",
    "        patt = cache['pattern', layer][0].detach().cpu().numpy()\n",
    "        display(cv.attention.attention_patterns(tokens=tokens, attention=patt, title=f'{name}: layer {layer} attention patterns'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Induction Heads via Ablation Sweep\n",
    "\n",
    "We use a purely behavioral criterion: *which head ablation reduces drift the most?*\n",
    "\n",
    "Metric: drift = max(P(X|{X,Y})) - min(P(X|{X,Y})) across the three sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ablation utilities\n",
    "\n",
    "from transformer_lens.utils import get_act_name\n",
    "\n",
    "def ablate_heads(heads):\n",
    "    # heads: list of (layer, head)\n",
    "    # Hook on z so the head contributes ~0 to residual stream.\n",
    "    layer_to_heads = {}\n",
    "    for layer, head in heads:\n",
    "        layer_to_heads.setdefault(int(layer), []).append(int(head))\n",
    "\n",
    "    hooks = []\n",
    "    for layer, hs in layer_to_heads.items():\n",
    "        hs = sorted(set(hs))\n",
    "        hook_name = get_act_name('z', layer)\n",
    "\n",
    "        def hook_fn(z, hook, hs=hs):\n",
    "            z[:, :, hs, :] = 0.0\n",
    "            return z\n",
    "\n",
    "        hooks.append((hook_name, hook_fn))\n",
    "    return hooks\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_sequences(fwd_hooks=None):\n",
    "    rows = []\n",
    "    for name, seq in SEQUENCES.items():\n",
    "        n_x, n_y = counts(seq)\n",
    "        prompt = make_prompt(seq)\n",
    "        logits = model(prompt) if fwd_hooks is None else model.run_with_hooks(prompt, fwd_hooks=fwd_hooks)\n",
    "        last = logits[0, -1, :]\n",
    "        probs = torch.softmax(last.float(), dim=-1)\n",
    "        p_x = float(probs[X_ID].item())\n",
    "        p_y = float(probs[Y_ID].item())\n",
    "        p_x_norm = p_x / (p_x + p_y) if (p_x + p_y) > 0 else 0.5\n",
    "\n",
    "        rows.append({\n",
    "            'name': name,\n",
    "            'p_X_norm': p_x_norm,\n",
    "            'logit_diff_XminusY': float(last[X_ID].item() - last[Y_ID].item()),\n",
    "            'bayes_p_X': bayes_p_x(n_x,n_y),\n",
    "            'freq_p_X': frequentist_p_x(n_x,n_y),\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    drift = float(df.p_X_norm.max() - df.p_X_norm.min())\n",
    "    mae_to_bayes = float((df.p_X_norm - df.bayes_p_X).abs().mean())\n",
    "    return df.sort_values('name'), drift, mae_to_bayes\n",
    "\n",
    "base_df, base_drift, base_mae = eval_sequences()\n",
    "print('Baseline drift:', base_drift)\n",
    "print('Baseline MAE to Bayes:', base_mae)\n",
    "display(base_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single-head ablation sweep: which head kills drift?\n",
    "\n",
    "results = []\n",
    "for layer in range(model.cfg.n_layers):\n",
    "    for head in range(model.cfg.n_heads):\n",
    "        hooks = ablate_heads([(layer, head)])\n",
    "        _, drift, mae = eval_sequences(fwd_hooks=hooks)\n",
    "        results.append({\n",
    "            'layer': layer,\n",
    "            'head': head,\n",
    "            'drift': drift,\n",
    "            'mae_to_bayes': mae,\n",
    "            'drift_reduction': base_drift - drift,\n",
    "        })\n",
    "\n",
    "df_sweep = pd.DataFrame(results).sort_values('drift_reduction', ascending=False)\n",
    "display(df_sweep.head(10))\n",
    "\n",
    "best = df_sweep.iloc[0].to_dict()\n",
    "print('Top drift-reducing head:', best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose induction-head candidates and re-test\n",
    "\n",
    "TOPK = 2  # increase if drift remains\n",
    "candidates = [(int(r.layer), int(r.head)) for r in df_sweep.head(TOPK).itertuples()]\n",
    "print('Ablating candidates:', candidates)\n",
    "\n",
    "hooks = ablate_heads(candidates)\n",
    "abl_df, abl_drift, abl_mae = eval_sequences(fwd_hooks=hooks)\n",
    "print('After ablation drift:', abl_drift, '(baseline:', base_drift, ')')\n",
    "print('After ablation MAE to Bayes:', abl_mae, '(baseline:', base_mae, ')')\n",
    "display(abl_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: visualize attention again (attention *patterns* won't change under z-ablation)\n",
    "\n",
    "import pkgutil\n",
    "from IPython.display import display\n",
    "\n",
    "if pkgutil.find_loader('circuitsvis') is None:\n",
    "    raise RuntimeError('circuitsvis not installed. Run: pip install circuitsvis')\n",
    "\n",
    "import circuitsvis as cv\n",
    "\n",
    "name = 'patterned'\n",
    "seq = SEQUENCES[name]\n",
    "prompt = make_prompt(seq)\n",
    "\n",
    "logits, cache = model.run_with_cache(prompt)\n",
    "tokens = model.to_str_tokens(prompt)\n",
    "\n",
    "print('Candidates:', candidates)\n",
    "print('Note: z-ablation changes contributions, not the attention weights themselves.')\n",
    "\n",
    "for layer in range(model.cfg.n_layers):\n",
    "    patt = cache['pattern', layer][0].detach().cpu().numpy()\n",
    "    display(cv.attention.attention_patterns(tokens=tokens, attention=patt, title=f'{name}: layer {layer} attention patterns (baseline)'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
